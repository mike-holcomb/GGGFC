def build_model_20190712_110058(num_channels):
    y0 = Input(shape=(32,32,3))
    y1 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y0)
    y2 = BatchNormalization()(y1)
    y3 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y2)
    y4 = BatchNormalization()(y3)
    y5 = LeakyReLU()(y4)
    y6 = Conv2D(1*num_channels, (1,1), padding='same', use_bias=False)(y5)
    y7 = BatchNormalization()(y6)
    y8 = LeakyReLU()(y7)
    y9 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y8)
    y10 = BatchNormalization()(y9)
    y11 = LeakyReLU()(y10)
    y12 = Conv2D(1*num_channels, (1,1), padding='same', use_bias=False)(y5)
    y13 = BatchNormalization()(y12)
    y14 = LeakyReLU()(y13)
    y15 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y14)
    y16 = BatchNormalization()(y15)
    y17 = LeakyReLU()(y16)
    y18 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y5)
    y19 = BatchNormalization()(y18)
    y20 = LeakyReLU()(y19)
    y21 = Conv2D(1*num_channels, (1,1), padding='same', use_bias=False)(y5)
    y22 = BatchNormalization()(y21)
    y23 = LeakyReLU()(y22)
    y24 = Conv2D(1*num_channels, (3,3), padding='same', use_bias=False)(y23)
    y25 = BatchNormalization()(y24)
    y26 = LeakyReLU()(y25)
    y27 = Concatenate()([y11, y17, y20, y26])
    y28 = Conv2D(4*num_channels, (1,1), padding='same', use_bias=False)(y27)
    y29 = BatchNormalization()(y28)
    y30 = LeakyReLU()(y29)
    y31 = Conv2D(4*num_channels, (3,3), padding='same', use_bias=False)(y30)
    y32 = BatchNormalization()(y31)
    y33 = LeakyReLU()(y32)
    y34 = Conv2D(4*num_channels, (1,1), padding='same', use_bias=False)(y33)
    y35 = BatchNormalization()(y34)
    y36 = LeakyReLU()(y35)
    y37 = Conv2D(4*num_channels, (3,3), padding='same', use_bias=False)(y36)
    y38 = BatchNormalization()(y37)
    y39 = LeakyReLU()(y38)
    y40 = MaxPooling2D(2,2,padding='same')(y39)
    y41 = Conv2D(8*num_channels, (3,3), padding='same', use_bias=False)(y40)
    y42 = BatchNormalization()(y41)
    y43 = LeakyReLU()(y42)
    y44 = Conv2D(8*num_channels, (3,3), padding='same', use_bias=False)(y43)
    y45 = BatchNormalization()(y44)
    y46 = LeakyReLU()(y45)
    y47 = Conv2D(8*num_channels, (3,3), padding='same', use_bias=False)(y43)
    y48 = BatchNormalization()(y47)
    y49 = LeakyReLU()(y48)
    y50 = Concatenate()([y46, y49])
    y51 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y50)
    y52 = BatchNormalization()(y51)
    y53 = LeakyReLU()(y52)
    y54 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y53)
    y55 = BatchNormalization()(y54)
    y56 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y55)
    y57 = BatchNormalization()(y56)
    y58 = LeakyReLU()(y57)
    y59 = Add()([y58, y53])
    y60 = Conv2D(16*num_channels, (1,1), padding='same', use_bias=False)(y50)
    y61 = BatchNormalization()(y60)
    y62 = LeakyReLU()(y61)
    y63 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y62)
    y64 = BatchNormalization()(y63)
    y65 = LeakyReLU()(y64)
    y66 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y65)
    y67 = BatchNormalization()(y66)
    y68 = Conv2D(16*num_channels, (3,3), padding='same', use_bias=False)(y67)
    y69 = BatchNormalization()(y68)
    y70 = LeakyReLU()(y69)
    y71 = Add()([y70, y65])
    y72 = Concatenate()([y59, y71])
    y73 = Conv2D(64*num_channels, (3,3), (2,2), padding='same', use_bias=False)(y72)
    y74 = BatchNormalization()(y73)
    y75 = LeakyReLU()(y74)
    y76 = Conv2D(64*num_channels, (1,1), padding='same', use_bias=False)(y75)
    y77 = BatchNormalization()(y76)
    y78 = LeakyReLU()(y77)
    y79 = Conv2D(64*num_channels, (3,3), padding='same', use_bias=False)(y78)
    y80 = BatchNormalization()(y79)
    y81 = LeakyReLU()(y80)
    y82 = Conv2D(64*num_channels, (3,3), padding='same', use_bias=False)(y81)
    y83 = BatchNormalization()(y82)
    y84 = LeakyReLU()(y83)
    y85 = Concatenate()([y84, y81])
    y86 = GlobalMaxPooling2D()(y85)
    y87 = Flatten()(y86)
    y88 = Dense(1024, use_bias=False)(y87)
    y89 = BatchNormalization()(y88)
    y90 = LeakyReLU()(y89)
    y91 = Dense(10, activation="softmax")(y90)
    y92 =  (y91)
    return Model(inputs=y0, outputs=y92)